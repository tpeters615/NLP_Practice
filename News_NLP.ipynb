{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text cleaning and preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://realpython.com/working-with-files-in-python/#listing-all-files-in-a-directory\n",
    "\n",
    "import os\n",
    "\n",
    "# List all files in a directory using os.listdir\n",
    "topics = ['Business', 'Entertainment', 'Politics','Sport', 'Tech']\n",
    "bus = []\n",
    "ent = []\n",
    "pol = []\n",
    "sport = []\n",
    "tech = []\n",
    "for topic in topics:\n",
    "    basepath = str(topic)+'/'\n",
    "    for entry in os.listdir(basepath):\n",
    "        if os.path.isfile(os.path.join(basepath, entry)):\n",
    "            if topic=='Business':\n",
    "                bus.append(entry)\n",
    "            elif topic=='Entertainment':\n",
    "                ent.append(entry)\n",
    "            elif topic=='Politics':\n",
    "                pol.append(entry)\n",
    "            elif topic=='Sport':\n",
    "                sport.append(entry)\n",
    "            elif topic=='Tech':\n",
    "                tech.append(entry)"
    
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "count_data = pd.DataFrame({'Business':[len(bus)], 'Entertainment': [len(ent)], 'Politics': [len(pol)], 'Sport':[len(sport)], 'Tech':[len(tech)]})\n",
    "count_data = count_data.transpose().reset_index()\n",
    "count_data.columns = ['Category', 'Count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fba3c1b00f0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAFECAYAAADcLn79AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAc70lEQVR4nO3de5QdZZ3u8e9DE9KMSTRAE2KCdJyJDgmXACGjXAUcLgJGFJwwwmQhRxZHUKJHmMAcD6gTzfK4FMFBJoIYb4R4hEnQGRUD4XYEciEIBFjkQIAekDRRIaBkSPidP+rt9E6nO73Tt+p+6/mstdeueqtq71/vpJ9d/VbVW4oIzMwsLzuVXYCZmfU9h7uZWYYc7mZmGXK4m5llyOFuZpahncsuAGCPPfaI5ubmssswMxtSVqxY8VJENHW2bFCEe3NzM8uXLy+7DDOzIUXSM10tc7eMmVmGHO5mZhlyuJuZZWhQ9LmbmW3PG2+8QUtLC6+//nrZpZSisbGR8ePHM2zYsLq3cbib2aDX0tLCyJEjaW5uRlLZ5QyoiGD9+vW0tLQwYcKEurdzt4yZDXqvv/46u+++e+WCHUASu++++w7/1eJwN7MhoYrB3qYnP7vD3cwsQ+5zN7Mhp3n2z/v09dbOPbnbdX73u98xa9Ysli1bxvDhw2lububKK6/kXe96V5/UsHTpUnbZZRcOO+ywPnm9bMK9r/+xe6qe/yRmZRgMvyND9fcjIjjttNOYOXMmCxYsAGDVqlW8+OKLfRruI0aM6LNwr6tbRtJaSQ9LWiVpeWrbTdJtkp5Mz6Nr1r9U0hpJT0g6oU8qNTMryR133MGwYcM4//zzt7RNmTKFI444gosvvpj99tuP/fffn5tuugkogvqUU07Zsu6FF17I9773PaAYbuXyyy/n4IMPZv/99+fxxx9n7dq1XHvttXzjG99gypQp3H333b2ueUf23I+JiJdq5mcDSyJirqTZaf4fJU0CZgCTgbcDv5b0rojY3OtqzcxK8Mgjj3DIIYds037zzTezatUqHnroIV566SUOPfRQjjrqqG5fb4899mDlypVcc801fO1rX+O6667j/PPPZ8SIEXzuc5/rk5p7c0B1OjA/Tc8HPlTTviAiNkbE08AaYFov3sfMbFC65557OPPMM2loaGDMmDEcffTRLFu2rNvtPvzhDwNwyCGHsHbt2n6prd5wD+BXklZIOi+1jYmIFwDS856pfRzwXM22LaltK5LOk7Rc0vLW1taeVW9mNgAmT57MihUrtmmPiE7X33nnnXnzzTe3zHc8R3348OEANDQ0sGnTpj6stF294X54RBwMnARcIGl7f3d0dkLmNp9ARMyLiKkRMbWpqdPhiM3MBoVjjz2WjRs38p3vfGdL27Jlyxg9ejQ33XQTmzdvprW1lbvuuotp06axzz77sHr1ajZu3MjLL7/MkiVLun2PkSNHsmHDhj6rua4+94h4Pj2vk3QLRTfLi5LGRsQLksYC69LqLcDeNZuPB57vs4rNrPIG+qwbSdxyyy3MmjWLuXPn0tjYuOVUyFdffZUDDzwQSXz1q19lr732AuCjH/0oBxxwABMnTuSggw7q9j1OPfVUTj/9dBYtWsTVV1/NkUce2buau/qzouaHeguwU0RsSNO3AV8EjgPW1xxQ3S0iLpE0GfgxxRfA24ElwMTtHVCdOnVq9PZmHYPhNC8Yuqd6Wf4Gw+9IT38/HnvsMfbdd98+rmZo6ewzkLQiIqZ2tn49e+5jgFvS5a87Az+OiF9IWgYslHQu8CxwBkBEPCppIbAa2ARc4DNlzMwGVrfhHhFPAQd20r6eYu+9s23mAHN6XZ2ZmfWIx5YxsyGhuy7knPXkZ3e4m9mg19jYyPr16ysZ8G3juTc2Nu7QdtmMLWNm+Ro/fjwtLS1U9ZqYtjsx7QiHu5kNesOGDduhuxCZu2XMzLLkcDczy5DD3cwsQw53M7MMOdzNzDLkcDczy5DD3cwsQw53M7MMOdzNzDLkcDczy5DD3cwsQw53M7MMOdzNzDLkcDczy5DD3cwsQw53M7MMOdzNzDLkcDczy5DD3cwsQw53M7MMOdzNzDLkcDczy5DD3cwsQw53M7MM7Vx2AWb9qXn2z8sugbVzTy67BKsg77mbmWXI4W5mliGHu5lZhuoOd0kNkh6U9LM0v5uk2yQ9mZ5H16x7qaQ1kp6QdEJ/FG5mZl3bkT33i4DHauZnA0siYiKwJM0jaRIwA5gMnAhcI6mhb8o1M7N61HW2jKTxwMnAHOCzqXk68L40PR9YCvxjal8QERuBpyWtAaYBv+mzqs3MeqEKZ1HVu+d+JXAJ8GZN25iIeAEgPe+Z2scBz9Ws15LatiLpPEnLJS1vbW3d4cLNzKxr3Ya7pFOAdRGxos7XVCdtsU1DxLyImBoRU5uamup8aTMzq0c93TKHAx+U9AGgERgl6YfAi5LGRsQLksYC69L6LcDeNduPB57vy6LNzGz7ut1zj4hLI2J8RDRTHCi9PSLOAhYDM9NqM4FFaXoxMEPScEkTgInAA31euZmZdak3ww/MBRZKOhd4FjgDICIelbQQWA1sAi6IiM29rtTMzOq2Q+EeEUspzoohItYDx3Wx3hyKM2usBIPhTADwmCpmZfIVqmZmGXK4m5llyOFuZpYhh7uZWYYc7mZmGXK4m5llyOFuZpYhh7uZWYYc7mZmGXK4m5llyOFuZpYhh7uZWYYc7mZmGXK4m5llyOFuZpYhh7uZWYYc7mZmGXK4m5llyOFuZpYhh7uZWYYc7mZmGXK4m5llyOFuZpYhh7uZWYYc7mZmGXK4m5llyOFuZpYhh7uZWYYc7mZmGXK4m5llyOFuZpahbsNdUqOkByQ9JOlRSV9I7btJuk3Sk+l5dM02l0paI+kJSSf05w9gZmbbqmfPfSNwbEQcCEwBTpT0HmA2sCQiJgJL0jySJgEzgMnAicA1khr6o3gzM+tct+EehVfT7LD0CGA6MD+1zwc+lKanAwsiYmNEPA2sAab1adVmZrZddfW5S2qQtApYB9wWEfcDYyLiBYD0vGdafRzwXM3mLamt42ueJ2m5pOWtra29+RnMzKyDusI9IjZHxBRgPDBN0n7bWV2dvUQnrzkvIqZGxNSmpqb6qjUzs7rs0NkyEfFHYClFX/qLksYCpOd1abUWYO+azcYDz/e6UjMzq1s9Z8s0SXpbmt4VeD/wOLAYmJlWmwksStOLgRmShkuaAEwEHujrws3MrGs717HOWGB+OuNlJ2BhRPxM0m+AhZLOBZ4FzgCIiEclLQRWA5uACyJic/+Ub2Zmnek23CPit8BBnbSvB47rYps5wJxeV2dmZj3iK1TNzDLkcDczy5DD3cwsQw53M7MMOdzNzDLkcDczy5DD3cwsQw53M7MMOdzNzDLkcDczy5DD3cwsQw53M7MMOdzNzDLkcDczy5DD3cwsQw53M7MMOdzNzDLkcDczy5DD3cwsQw53M7MMOdzNzDLkcDczy5DD3cwsQw53M7MMOdzNzDLkcDczy5DD3cwsQw53M7MMOdzNzDLkcDczy5DD3cwsQw53M7MMdRvukvaWdIekxyQ9Kumi1L6bpNskPZmeR9dsc6mkNZKekHRCf/4AZma2rXr23DcB/yMi9gXeA1wgaRIwG1gSEROBJWmetGwGMBk4EbhGUkN/FG9mZp3rNtwj4oWIWJmmNwCPAeOA6cD8tNp84ENpejqwICI2RsTTwBpgWl8XbmZmXduhPndJzcBBwP3AmIh4AYovAGDPtNo44LmazVpSW8fXOk/ScknLW1tbd7xyMzPrUt3hLmkE8FNgVkS8sr1VO2mLbRoi5kXE1IiY2tTUVG8ZZmZWh7rCXdIwimD/UUTcnJpflDQ2LR8LrEvtLcDeNZuPB57vm3LNzKwe9ZwtI+B64LGI+HrNosXAzDQ9E1hU0z5D0nBJE4CJwAN9V7KZmXVn5zrWORw4G3hY0qrUdhkwF1go6VzgWeAMgIh4VNJCYDXFmTYXRMTmPq/czMy61G24R8Q9dN6PDnBcF9vMAeb0oi4zM+sFX6FqZpYhh7uZWYYc7mZmGXK4m5llyOFuZpYhh7uZWYYc7mZmGXK4m5llyOFuZpYhh7uZWYYc7mZmGXK4m5llyOFuZpYhh7uZWYYc7mZmGXK4m5llyOFuZpYhh7uZWYYc7mZmGXK4m5llyOFuZpYhh7uZWYYc7mZmGXK4m5llyOFuZpYhh7uZWYYc7mZmGXK4m5llyOFuZpYhh7uZWYYc7mZmGeo23CV9V9I6SY/UtO0m6TZJT6bn0TXLLpW0RtITkk7or8LNzKxr9ey5fw84sUPbbGBJREwElqR5JE0CZgCT0zbXSGros2rNzKwu3YZ7RNwF/L5D83RgfpqeD3yopn1BRGyMiKeBNcC0PqrVzMzq1NM+9zER8QJAet4ztY8DnqtZryW1bUPSeZKWS1re2trawzLMzKwzfX1AVZ20RWcrRsS8iJgaEVObmpr6uAwzs2rrabi/KGksQHpel9pbgL1r1hsPPN/z8szMrCd6Gu6LgZlpeiawqKZ9hqThkiYAE4EHeleimZntqJ27W0HSjcD7gD0ktQCXA3OBhZLOBZ4FzgCIiEclLQRWA5uACyJicz/VbmZmXeg23CPizC4WHdfF+nOAOb0pyszMesdXqJqZZcjhbmaWIYe7mVmGHO5mZhlyuJuZZcjhbmaWIYe7mVmGHO5mZhlyuJuZZcjhbmaWIYe7mVmGHO5mZhlyuJuZZcjhbmaWIYe7mVmGHO5mZhlyuJuZZcjhbmaWIYe7mVmGHO5mZhlyuJuZZcjhbmaWIYe7mVmGHO5mZhlyuJuZZcjhbmaWIYe7mVmGHO5mZhlyuJuZZcjhbmaWIYe7mVmGHO5mZhnqt3CXdKKkJyStkTS7v97HzMy21S/hLqkB+BfgJGAScKakSf3xXmZmtq3+2nOfBqyJiKci4r+ABcD0fnovMzPrQBHR9y8qnQ6cGBH/Lc2fDfxNRFxYs855wHlp9t3AE31eyI7bA3ip7CIGCX8W7fxZtPNn0W4wfBb7RERTZwt27qc3VCdtW32LRMQ8YF4/vX+PSFoeEVPLrmMw8GfRzp9FO38W7Qb7Z9Ff3TItwN418+OB5/vpvczMrIP+CvdlwERJEyTtAswAFvfTe5mZWQf90i0TEZskXQj8EmgAvhsRj/bHe/WxQdVNVDJ/Fu38WbTzZ9FuUH8W/XJA1czMyuUrVM3MMuRwNzPLkMPdzCxDDncz65Kkw+tpqwoV9pT09rZH2TV1pfLhLukiSaPSP9r1klZKOr7susog6Qf1tFWBpDMkjUzT/1PSzZIOLruuElxdZ1v2JH0SaAXuBpakx69LLWo7+usK1aHk4xHxTUknAE3AOcANwK/KLasUk2tn0gBwh5RUS9k+HxE/kXQEcALwNeDbwN+UW9bAkPRe4DCgSdJnaxaNoji9uYo+C+wbEa1lF1KPyu+50z5UwgeAGyLiITofPiFbki6VtAE4QNIr6bEBWAcsKrm8smxOzycD346IRcAuJdYz0HYBRlDsAI6sebwCnF5iXWVqAX5fdhH1qvx57pJuAMYBE4ADKfZKlkZE5fZYJX0lIi4tu47BQNLPgP8E3k/x18ufgQci4sBSCxtA6S+3myKiqmEOgKRPp8kDgInAz4CNbcsj4qoy6uqOw13aCZgCPBURf5S0GzA+In5bcmmlkDQO2IeaLruIuKu8isoh6S+AE4GHI+JJSWOB/SOiUt11km6PiGPLrqNMkr60veUR8fmBqmVHuM8d3gusiojXJJ0FHAx8s+SaSiFpLsU4QKtp75YIoHLhTrGXdltEbEjzrwIvl1hPWR6UtBj4CfBaW2NE3FxeSQNrsIZ3d7znLv2WojvmAOAHwPXAhyPi6FILK4GkJ4ADImJjtytnTtKDwMGRfkHSX3jLI6JSZ8ykbsuOIiI+PuDFlEzSL4AZEfHHND8a+GFEnFxuZZ3znjtsioiQNB34ZkRcL2lm2UWV5ClgGDX9iRWmqNnziYg3JVXu9yUizim7hkFkr7ZgB4iIPwzm89wr95+1ExskXQqcDRyZDiINK7mmsvwJWCVpCVsfMPp015tk66l0IO3baf6TFF9+lSJpPMV57YdTdNHdA1wUES2lFlaOzZLGt/3skt5RdkHb424ZaS/g74FlEXF3+gd7X0R8v+TSBlxXf7FExPyBrqVskvYErgKOpQi1JcCsiFhXamEDTNJtwI8puiwBzgI+FhF/W15V5ZB0MnANcHtqOgb47xHxH+VV1bXKhzuApH2AiRHx63SWREPNgbRKkbQr8I6IGAz3tLWSSVoVEVO6a6sKSWMoTsIQcO9g/rKv/EVMkj4B/B/gX1PTOODfyquoPJJOBVYBv0jzU9KZEpUh6ZL0fLWkqzo+yq6vBC9JOktSQ3qcBawvu6gSHQNMjohbgOGSBu31MO5zhwuAacD9AOmc5j3LLak0V1B8FksBImKVpAllFlSCx9Lz8lKrGDw+DnwL+Eaavze1VY6kb1EcjzsKmENxaui1wKFl1tUVhztsjIj/kooRB9IZEVXtq9oUES+3fRZJpT6LiLg1Tf4pIn5Su0zSGSWUVKqIeBb4YNl1DBKHRcTB6TRZIuL36R7Rg1Llu2WAOyVdBuwq6W8pLta4tZttcvWIpL8HGiRNlHQ18H/LLqoknQ3DULmhGSS9U9KtklolrZO0SNI7y66rJG+k6x3arn3YHXiz3JK6VvkDqukf61zgeIqDJL8ErosKfjDpYPI/sfVn8aWIeL3UwgaQpJMoBpH7KHBTzaJRwKSImFZKYSWRdB/wL8CNqWkG8KmIqMTomFD8NR8RmyT9A3AaMBX4LsX/kS9ExIJSC+xC5cPdrJakAynGGvoi8L9qFm0A7oiIP5RSWEkk3d8xyCXdFxHvKaumgSZpZduVyZImUwwmJ+DXEfFIqcVtR+XDXcVdZa6gfbAsUVxeXbk/PSVNBS4Dmtl64LADyqqpLG17a2XXUbY03tAfgQUU3RF/Bwyn2JsnIobMELg9JenBiDio7Dp2lMNdehz4DLCC9sGyiIjKne6Vxpa5GHiYmr7EiHimtKIGmKSFEfFRSQ/TycHkqn3RSXo6TbZ9FrVH2yuxEySpBfh6V8sjostlZfLZMvDyYL3CrAStEVGp89o7cVF6PqXUKkom6VDguYiYkOZnAh8B1gJXVGGPvUYDxY1LhtRNfLznXvzZ2QDczNbjqawsraiSSDoOOJPiUvvaz6Iyw7taQdJK4P3pdL+jKLplPkVxPGLfKt3Ao7bPfSjxnnv7PTGn1rQFxZgiVXMO8NcUF2q0dcsExRdfJaTbC9bu8SjNtx2LGVVKYQOvoWbv/O+AeRHxU+CnklaVWFcZhtQee5vKh3tEHFN2DYPIgRGxf9lFlCkiRpZdwyDRUHNQ+TjgvJplVcuN48ouoCeq9o+0haSzIuKHHe7svsVgPUjSz+6TNCkiVpddyGCQTos8Ms3eVbFbL95IcYHfSxT3j70bQNJfUbE7Ug3V4wuVDXfgLenZe2rtjgBmpjMkNtLeFVGpM0QAJF0EfIL2LqkfSZoXEVeXWNaAiYg5aVz/scCvai7q24mi790GucofULV2aejjbVTpVMg26faL742I19L8W4DfVPGLzoamyo8tI+mrkkZJGiZpiaSX0rCmlZNCvAV4g+IgYtujikTNdQ9pekgeWLNqqnK3TJvjI+ISSadRBNsZwB3AD8sta+BJ+hRwOfAiW58tU8W91RuA+yXdkuY/RHHzdLMhweHefr/UDwA3pvN6y6ynTBcB767i1bkdRcTXJS2lOA4h4JyIeLDcqszq53CHW9MQBH8GPimpCajMKIgdPEfFzoToSFIjcD7wVxTDMFzjMWZsKPIBVUDSaOCViNichr0dFRG/K7uugSbpeuDdwM/Z+grVypwWKukmimMOdwMnAWsjYla5VZntuMrvuacxmtumaxd9f+CrKd2z6bFLelTRpLYLudKX3QMl12PWI5UPd7a+/2EjxdVoK6lguEfEF8quYRB4o20i3aChzFrMeszdMh1Ieivwg4iozH0jJV0ZEbMk3Urnw9xW6bPYTHHjYygOpO4K/InqjS1jQ5z33Lf1J2Bi2UUMsB+k56+VWsUgEBENZddg1hcqH+4d9lZ3AiYBC8uraOBFxIr0fGfZtZhZ36h8t4yko2tmNwHPRERLWfWUSdJE4CsUX3CNbe1VuNuOWW4qv+deu7cqaQ+gyhfw3EBxheo3gGMoxnf3EUWzIaiyY8tIeo+kpZJulnSQpEeAR4AXJZ1Ydn0l2TUillD8RfdMRFxBNW9aYjbkVXnP/VvAZcBbgduBkyLiPkl/TTGW9S/KLK4kr0vaCXhS0oXAfwJ7llyTmfVAZfvcJa2KiClp+rGI2Ldm2YMRcVB51ZUj3RT5MeBtwJeAUcBXI+L+Ugszsx1W2W4Z2kc9hGJcmVrV/MaD5oh4NSJaIuKciPgI8I6yizKzHVflPfe2i1VqL1QhzTdGxLCuts1VZ3d5H6p3fjerusr2uftilXaSTqIY8nicpKtqFo2iOD3UzIaYyoa7beV5YDnwQWBFTfsG4DOlVGRmvVLZbhnbmqQG4PsR8bGyazGz3qvyAVWrERGbgd0lVXWoX7OsuFvGaj0D3CtpMe0jI1bqZh1muXC4W63n02MnYGTJtZhZL7jP3bYh6S0R8Vr3a5rZYOU+d9tC0nslraa4ShVJB0q6puSyzKwHHO5W60rgBNLImBHxEHBUqRWZWY843G0rEfFch6bNpRRiZr3iA6pW6zlJhwGRTon8NKmLxsyGFh9QtS3SzUq+CbyfYoydXwGfjojfl1qYme0wh7ttIenwiLi3uzYzG/wc7raFR4U0y4f73A1J7wUOA5okfbZm0SjAo2eaDUEOdwPYBRhB8f+h9srUV4DTS6nIzHrF3TK2haR9IuKZsusws97znrvVGi5pHtBMzf+NiDi2tIrMrEe8525bSHoIuJbihh1bLl6KiBVdbmRmg5LD3baQtCIiDim7DjPrPYe7bSHpCmAdcAuwsa3dFzGZDT0Od9tC0tOdNEdEvHPAizGzXnG4m5llyKNCGpIuqZk+o8OyLw98RWbWWw53A5hRM31ph2UnDmQhZtY3HO4GxQiQnU13Nm9mQ4DD3QCii+nO5s1sCPABVUPSZuA1ir30XYE/tS0CGiNiWFm1mVnPONzNzDLkbhkzsww53M3MMuRwt6xI2kvSAkn/T9JqSf8u6V1drPs2SZ8c6BrNBoLD3bIhSRTj4iyNiL+MiEnAZcCYLjZ5G9Dv4S7JQ2vbgHO4W06OAd6IiGvbGiJiFfCgpCWSVkp6WNL0tHgu8JeSVkn63wCSLpa0TNJvJX2h7XUkfV7S45Juk3SjpM+l9imS7kvr3yJpdGpfKunLku4E/knS05KGpWWjJK1tmzfrD96jsJzsRzEWfUevA6dFxCuS9gDuk7QYmA3sFxFTACQdD0wEplGcBrpY0lEUp4Z+BDiI4ndmZc37fB/4VETcKemLwOXArLTsbRFxdHrtZuBk4N8orgj+aUS80Yc/u9lWHO5WBQK+nIL6TWAcnXfVHJ8eD6b5ERRhPxJYFBF/BpB0a3p+K0WA35nWnw/8pOb1bqqZvg64hCLczwE+0fsfy6xrDnfLyaN0fkPvjwFNwCER8YaktUBjJ+sJ+EpE/OtWjdJneljPa20TEXGvpGZJRwMNEfFID1/TrC7uc7ec3E5xH9gte8WSDgX2AdalYD8mzQNsoNgrb/NL4OOSRqRtx0naE7gHOFVSY1p2MkBEvAz8QdKRafuzgTvp2veBG4EbevlzmnXLe+6WjYgISacBV0qaTdHXvha4ArhK0nJgFfB4Wn+9pHslPQL8R0RcLGlf4DfFiTe8CpwVEctSH/1DwDPAcuDl9LYzgWsl/QXwFEWXS1d+BPwzRcCb9SsPP2BWB0kjIuLVFOJ3AedFxModfI3TgekRcXa/FGlWw3vuZvWZJ2kSRV/9/B4E+9XAScAH+qM4s468525mliEfUDUzy5DD3cwsQw53M7MMOdzNzDLkcDczy9D/B08agK2OTPT+AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "count_data.plot(kind='bar', x = 'Category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating data table of file name, contents, category\n",
    "news_data = pd.DataFrame(columns=['File_Name', 'Contents', 'Category'])\n",
    "for file in bus:\n",
    "    with open(\"Business/\"+file, mode='r') as reader:\n",
    "        content = \"\"\n",
    "        for line in reader.readlines():\n",
    "            content=content+line\n",
    "    addition = pd.DataFrame({'File_Name':file, 'Contents': [content], 'Category': 'Business'})\n",
    "    news_data = pd.concat([news_data, addition], axis=0)\n",
    "for file in ent:\n",
    "    with open(\"Entertainment/\"+file, mode='r') as reader:\n",
    "        content = \"\"\n",
    "        for line in reader.readlines():\n",
    "            content=content+line\n",
    "    addition = pd.DataFrame({'File_Name':file, 'Contents': [content], 'Category': 'Entertainment'})\n",
    "    news_data = pd.concat([news_data, addition], axis=0)\n",
    "for file in pol:\n",
    "    with open(\"Politics/\"+file, mode='r') as reader:\n",
    "        content = \"\"\n",
    "        for line in reader.readlines():\n",
    "            content=content+line\n",
    "    addition = pd.DataFrame({'File_Name':file, 'Contents': [content], 'Category': 'Politics'})\n",
    "    news_data = pd.concat([news_data, addition], axis=0)\n",
    "for file in sport:\n",
    "    with open(\"Sport/\"+file, mode='r') as reader:\n",
    "        content = \"\"\n",
    "        try: \n",
    "            for line in reader.readlines():\n",
    "                content=content+line\n",
    "            addition = pd.DataFrame({'File_Name':file, 'Contents': [content], 'Category': 'Sport'})\n",
    "            news_data = pd.concat([news_data, addition], axis=0)\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "for file in tech:\n",
    "    with open(\"Tech/\"+file, mode='r') as reader:\n",
    "        content = \"\"\n",
    "        for line in reader.readlines():\n",
    "            content=content+line\n",
    "    addition = pd.DataFrame({'File_Name':file, 'Contents': [content], 'Category': 'Technology'})\n",
    "    news_data = pd.concat([news_data, addition], axis=0)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "news_data['Content'] = news_data[['Contents']].replace(to_replace=\"[\\n|\\r|\\\"|?|:|!|\\.|,|;|']\", value=' ', regex=True)\n",
    "news_data.drop('Contents', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File_Name</th>\n",
       "      <th>Category</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>010.txt</td>\n",
       "      <td>Business</td>\n",
       "      <td>court rejects $280bn tobacco case  a us govern...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>011.txt</td>\n",
       "      <td>Business</td>\n",
       "      <td>ask jeeves tips online ad revival  ask jeeves ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>015.txt</td>\n",
       "      <td>Business</td>\n",
       "      <td>air passengers win new eu rights  air passenge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>026.txt</td>\n",
       "      <td>Business</td>\n",
       "      <td>safety alert as gm recalls cars  the world s b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>030.txt</td>\n",
       "      <td>Business</td>\n",
       "      <td>soaring oil  hits world economy   the soaring ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2219</th>\n",
       "      <td>376.txt</td>\n",
       "      <td>Technology</td>\n",
       "      <td>t-mobile bets on  pocket office   t-mobile has...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2220</th>\n",
       "      <td>382.txt</td>\n",
       "      <td>Technology</td>\n",
       "      <td>tough rules for ringtone sellers  firms that f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2221</th>\n",
       "      <td>387.txt</td>\n",
       "      <td>Technology</td>\n",
       "      <td>progress on new internet domains  by early 200...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222</th>\n",
       "      <td>389.txt</td>\n",
       "      <td>Technology</td>\n",
       "      <td>mobile multimedia slow to catch on  there is n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223</th>\n",
       "      <td>392.txt</td>\n",
       "      <td>Technology</td>\n",
       "      <td>broadband fuels online expression  fast web ac...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2224 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     File_Name    Category                                            Content\n",
       "0      010.txt    Business  court rejects $280bn tobacco case  a us govern...\n",
       "1      011.txt    Business  ask jeeves tips online ad revival  ask jeeves ...\n",
       "2      015.txt    Business  air passengers win new eu rights  air passenge...\n",
       "3      026.txt    Business  safety alert as gm recalls cars  the world s b...\n",
       "4      030.txt    Business  soaring oil  hits world economy   the soaring ...\n",
       "...        ...         ...                                                ...\n",
       "2219   376.txt  Technology  t-mobile bets on  pocket office   t-mobile has...\n",
       "2220   382.txt  Technology  tough rules for ringtone sellers  firms that f...\n",
       "2221   387.txt  Technology  progress on new internet domains  by early 200...\n",
       "2222   389.txt  Technology  mobile multimedia slow to catch on  there is n...\n",
       "2223   392.txt  Technology  broadband fuels online expression  fast web ac...\n",
       "\n",
       "[2224 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_data['Content'] = news_data['Content'].str.lower()\n",
    "news_data.reset_index(inplace=True)\n",
    "news_data.drop(['index'], inplace=True,axis=1)\n",
    "news_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/75/ce35194d8e3022203cca0d2f896dbb88689f9b3fce8e9f9cff942913519d/nltk-3.5.zip (1.4MB)\n",
      "\u001b[K     |████████████████████████████████| 1.4MB 3.7MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting click (from nltk)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d2/3d/fa76db83bf75c4f8d338c2fd15c8d33fdd7ad23a9b5e57eb6c5de26b430e/click-7.1.2-py2.py3-none-any.whl (82kB)\n",
      "\u001b[K     |████████████████████████████████| 92kB 7.7MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting joblib (from nltk)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b8/a6/d1a816b89aa1e9e96bcb298eb1ee1854f21662ebc6d55ffa3d7b3b50122b/joblib-0.15.1-py3-none-any.whl (298kB)\n",
      "\u001b[K     |████████████████████████████████| 307kB 28.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting regex (from nltk)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/7c/0d46b10a87b3087e8e303fac923beb19ec839d7c5ea34971a12fafb22b52/regex-2020.5.14-cp36-cp36m-manylinux2010_x86_64.whl (675kB)\n",
      "\u001b[K     |████████████████████████████████| 686kB 31.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tqdm (from nltk)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c9/40/058b12e8ba10e35f89c9b1fdfc2d4c7f8c05947df2d5eb3c7b258019fda0/tqdm-4.46.0-py2.py3-none-any.whl (63kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 21.1MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: nltk\n",
      "  Building wheel for nltk (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jupyterlab/.cache/pip/wheels/ae/8c/3f/b1fe0ba04555b08b57ab52ab7f86023639a526d8bc8d384306\n",
      "Successfully built nltk\n",
      "Installing collected packages: click, joblib, regex, tqdm, nltk\n",
      "Successfully installed click-7.1.2 joblib-0.15.1 nltk-3.5 regex-2020.5.14 tqdm-4.46.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jupyterlab/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/jupyterlab/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## lemmatizing each word \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "# word and sent tokenizers \n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "nrows = news_data.shape[0]\n",
    "lemmatized_text_list = []\n",
    "\n",
    "for row in range(0, nrows):\n",
    "    \n",
    "    # Save the text and its words into an object\n",
    "    text_array = news_data.at[row,'Content']\n",
    "    text_words = text_array.split()\n",
    "\n",
    "    # Create an empty list containing lemmatized words\n",
    "    lemmatized_list = []\n",
    "    \n",
    "    # Iterate through every word to lemmatize\n",
    "    for word in text_words:\n",
    "        lemmatized_list.append(wordnet_lemmatizer.lemmatize(word, pos=\"v\"))\n",
    "        \n",
    "    # Join the list\n",
    "    lemmatized_text = \" \".join(lemmatized_list)\n",
    "    \n",
    "    # Append to the list containing the texts\n",
    "    lemmatized_text_list.append(lemmatized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File_Name</th>\n",
       "      <th>Category</th>\n",
       "      <th>Content</th>\n",
       "      <th>Lemma_Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>010.txt</td>\n",
       "      <td>Business</td>\n",
       "      <td>court rejects $280bn tobacco case  a us govern...</td>\n",
       "      <td>court reject $280bn tobacco case a us governme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>011.txt</td>\n",
       "      <td>Business</td>\n",
       "      <td>ask jeeves tips online ad revival  ask jeeves ...</td>\n",
       "      <td>ask jeeves tip online ad revival ask jeeves ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>015.txt</td>\n",
       "      <td>Business</td>\n",
       "      <td>air passengers win new eu rights  air passenge...</td>\n",
       "      <td>air passengers win new eu right air passengers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>026.txt</td>\n",
       "      <td>Business</td>\n",
       "      <td>safety alert as gm recalls cars  the world s b...</td>\n",
       "      <td>safety alert as gm recall cars the world s big...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>030.txt</td>\n",
       "      <td>Business</td>\n",
       "      <td>soaring oil  hits world economy   the soaring ...</td>\n",
       "      <td>soar oil hit world economy the soar cost of oi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  File_Name  Category                                            Content  \\\n",
       "0   010.txt  Business  court rejects $280bn tobacco case  a us govern...   \n",
       "1   011.txt  Business  ask jeeves tips online ad revival  ask jeeves ...   \n",
       "2   015.txt  Business  air passengers win new eu rights  air passenge...   \n",
       "3   026.txt  Business  safety alert as gm recalls cars  the world s b...   \n",
       "4   030.txt  Business  soaring oil  hits world economy   the soaring ...   \n",
       "\n",
       "                                       Lemma_Content  \n",
       "0  court reject $280bn tobacco case a us governme...  \n",
       "1  ask jeeves tip online ad revival ask jeeves ha...  \n",
       "2  air passengers win new eu right air passengers...  \n",
       "3  safety alert as gm recall cars the world s big...  \n",
       "4  soar oil hit world economy the soar cost of oi...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_data['Lemma_Content'] = lemmatized_text_list\n",
    "news_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/jupyterlab/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = list(stopwords.words('english'))\n",
    "n = news_data.shape[0]\n",
    "Content = []\n",
    "for i in range(0,n):\n",
    "    entry_list = []\n",
    "    text_list = news_data.at[i,'Lemma_Content']\n",
    "    text_list = text_list.split(' ')  \n",
    "    for w in text_list:\n",
    "        if w not in stop_words:\n",
    "            entry_list.append(w)\n",
    "    s = \" \"\n",
    "    entry_text = s.join(entry_list)\n",
    "    Content.append(entry_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data['Content'] = Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File_Name</th>\n",
       "      <th>Category</th>\n",
       "      <th>Content</th>\n",
       "      <th>Lemma_Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>010.txt</td>\n",
       "      <td>Business</td>\n",
       "      <td>court reject $280bn tobacco case us government...</td>\n",
       "      <td>court reject $280bn tobacco case a us governme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>011.txt</td>\n",
       "      <td>Business</td>\n",
       "      <td>ask jeeves tip online ad revival ask jeeves be...</td>\n",
       "      <td>ask jeeves tip online ad revival ask jeeves ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>015.txt</td>\n",
       "      <td>Business</td>\n",
       "      <td>air passengers win new eu right air passengers...</td>\n",
       "      <td>air passengers win new eu right air passengers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>026.txt</td>\n",
       "      <td>Business</td>\n",
       "      <td>safety alert gm recall cars world biggest carm...</td>\n",
       "      <td>safety alert as gm recall cars the world s big...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>030.txt</td>\n",
       "      <td>Business</td>\n",
       "      <td>soar oil hit world economy soar cost oil hit g...</td>\n",
       "      <td>soar oil hit world economy the soar cost of oi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  File_Name  Category                                            Content  \\\n",
       "0   010.txt  Business  court reject $280bn tobacco case us government...   \n",
       "1   011.txt  Business  ask jeeves tip online ad revival ask jeeves be...   \n",
       "2   015.txt  Business  air passengers win new eu right air passengers...   \n",
       "3   026.txt  Business  safety alert gm recall cars world biggest carm...   \n",
       "4   030.txt  Business  soar oil hit world economy soar cost oil hit g...   \n",
       "\n",
       "                                       Lemma_Content  \n",
       "0  court reject $280bn tobacco case a us governme...  \n",
       "1  ask jeeves tip online ad revival ask jeeves ha...  \n",
       "2  air passengers win new eu right air passengers...  \n",
       "3  safety alert as gm recall cars the world s big...  \n",
       "4  soar oil hit world economy the soar cost of oi...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Coding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categories dictionary\n",
    "category_codes = {\n",
    "    'Business': 0,\n",
    "    'Entertainment': 1,\n",
    "    'Politics': 2,\n",
    "    'Sport': 3,\n",
    "    'Technology': 4\n",
    "}\n",
    "news_data_original = news_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_data['Category_Code'] = news_data['Category']\n",
    "news_data = news_data.replace({'Category_Code':category_codes})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#news_data.drop(['Lemma_Content'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File_Name</th>\n",
       "      <th>Category</th>\n",
       "      <th>Content</th>\n",
       "      <th>Category_Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>010.txt</td>\n",
       "      <td>Business</td>\n",
       "      <td>court reject $280bn tobacco case us government...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>011.txt</td>\n",
       "      <td>Business</td>\n",
       "      <td>ask jeeves tip online ad revival ask jeeves be...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>015.txt</td>\n",
       "      <td>Business</td>\n",
       "      <td>air passengers win new eu right air passengers...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>026.txt</td>\n",
       "      <td>Business</td>\n",
       "      <td>safety alert gm recall cars world biggest carm...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>030.txt</td>\n",
       "      <td>Business</td>\n",
       "      <td>soar oil hit world economy soar cost oil hit g...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2219</th>\n",
       "      <td>376.txt</td>\n",
       "      <td>Technology</td>\n",
       "      <td>t-mobile bet pocket office t-mobile launch lat...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2220</th>\n",
       "      <td>382.txt</td>\n",
       "      <td>Technology</td>\n",
       "      <td>tough rule ringtone sellers firm flout rule ri...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2221</th>\n",
       "      <td>387.txt</td>\n",
       "      <td>Technology</td>\n",
       "      <td>progress new internet domains early 2005 net c...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222</th>\n",
       "      <td>389.txt</td>\n",
       "      <td>Technology</td>\n",
       "      <td>mobile multimedia slow catch doubt mobile phon...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223</th>\n",
       "      <td>392.txt</td>\n",
       "      <td>Technology</td>\n",
       "      <td>broadband fuel online expression fast web acce...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2224 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     File_Name    Category                                            Content  \\\n",
       "0      010.txt    Business  court reject $280bn tobacco case us government...   \n",
       "1      011.txt    Business  ask jeeves tip online ad revival ask jeeves be...   \n",
       "2      015.txt    Business  air passengers win new eu right air passengers...   \n",
       "3      026.txt    Business  safety alert gm recall cars world biggest carm...   \n",
       "4      030.txt    Business  soar oil hit world economy soar cost oil hit g...   \n",
       "...        ...         ...                                                ...   \n",
       "2219   376.txt  Technology  t-mobile bet pocket office t-mobile launch lat...   \n",
       "2220   382.txt  Technology  tough rule ringtone sellers firm flout rule ri...   \n",
       "2221   387.txt  Technology  progress new internet domains early 2005 net c...   \n",
       "2222   389.txt  Technology  mobile multimedia slow catch doubt mobile phon...   \n",
       "2223   392.txt  Technology  broadband fuel online expression fast web acce...   \n",
       "\n",
       "      Category_Code  \n",
       "0                 0  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                 0  \n",
       "4                 0  \n",
       "...             ...  \n",
       "2219              4  \n",
       "2220              4  \n",
       "2221              4  \n",
       "2222              4  \n",
       "2223              4  \n",
       "\n",
       "[2224 rows x 4 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train - Test Split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(news_data['Content'], \n",
    "                                                    news_data['Category_Code'], \n",
    "                                                    test_size=0.15, \n",
    "                                                    random_state=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Representation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1890, 300)\n",
      "(334, 300)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Parameter election\n",
    "ngram_range = (1,2)\n",
    "min_df = 10\n",
    "max_df = 1.\n",
    "max_features = 300\n",
    "\n",
    "tfidf = TfidfVectorizer(encoding='utf-8',\n",
    "                        ngram_range=ngram_range,\n",
    "                        stop_words=None,\n",
    "                        lowercase=False,\n",
    "                        max_df=max_df,\n",
    "                        min_df=min_df,\n",
    "                        max_features=max_features,\n",
    "                        norm='l2',\n",
    "                        sublinear_tf=True)\n",
    "\n",
    "features_train = tfidf.fit_transform(X_train).toarray()\n",
    "labels_train = y_train\n",
    "print(features_train.shape)\n",
    "\n",
    "features_test = tfidf.transform(X_test).toarray()\n",
    "labels_test = y_test\n",
    "print(features_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hit': 121, 'media': 170, 'player': 209, 'phone': 205, 'game': 105, 'go': 109, 'price': 215, 'uk': 279, 'us': 281, 'europe': 81, 'next': 192, 'include': 128, 'great': 112, 'british': 38, 'face': 87, 'make': 163, 'lot': 161, 'want': 287, 'use': 282, 'play': 208, 'music': 183, 'take': 260, 'digital': 73, 'like': 151, 'mobile': 175, 'send': 241, 'mail': 162, 'service': 242, 'people': 204, 'pay': 203, 'also': 13, 'work': 294, 'system': 259, 'support': 258, 'mean': 169, 'london': 156, 'although': 14, 'list': 154, 'three': 270, 'name': 184, 'likely': 152, 'come': 54, 'cost': 60, 'far': 89, 'first': 96, 'two': 278, '000': 0, 'sell': 240, 'better': 30, 'european': 82, 'months': 178, 'later': 144, 'month': 177, 'expect': 86, 'could': 61, 'side': 246, 'former': 101, 'minister': 174, 'ireland': 135, 'announce': 15, 'long': 157, 'year': 297, 'old': 197, 'deal': 69, 'security': 238, 'future': 104, 'new': 190, 'create': 65, 'hold': 122, 'government': 111, 'leave': 148, 'become': 26, 'december': 70, 'follow': 98, 'find': 94, 'police': 212, 'party': 202, 'back': 22, 'claim': 51, 'say': 235, 'despite': 72, 'get': 107, 'public': 219, 'right': 230, 'bill': 33, 'action': 9, 'call': 43, 'year old': 298, 'head': 118, 'court': 64, 'oil': 196, 'company': 55, 'continue': 58, 'firm': 95, 'break': 35, 'tax': 262, 'file': 91, 'hop': 124, 'international': 133, 'business': 41, 'law': 146, 'force': 99, 'however': 127, 'state': 255, 'buy': 42, 'every': 84, 'market': 166, 'one': 198, 'bank': 23, 'six': 249, 'win': 292, 'decision': 71, 'would': 296, 'case': 45, 'chance': 46, 'president': 214, 'country': 63, 'top': 273, 'think': 268, 'spokesman': 252, 'real': 222, 'mr': 180, 'charge': 48, 'five': 97, 'million': 173, 'figure': 90, 'rise': 231, 'level': 149, 'last': 142, 'labour': 141, 'january': 137, '12': 2, 'high': 120, 'since': 248, 'change': 47, 'way': 289, 'number': 193, 'see': 239, 'well': 291, 'put': 220, 'end': 79, 'rule': 232, 'may': 168, 'look': 158, 'job': 138, 'add': 10, 'cut': 67, 'begin': 27, 'term': 267, 'china': 50, 'net': 188, 'set': 243, 'years': 299, 'report': 227, 'users': 283, 'many': 165, 'nations': 186, 'already': 12, 'chief': 49, 'executive': 85, 'hard': 117, 'time': 271, 'line': 153, 'help': 119, 'home': 123, 'accord': 7, 'even': 83, 'internet': 134, 'still': 256, 'much': 182, 'live': 155, 'biggest': 32, 'keep': 139, 'meet': 171, 'life': 150, 'foreign': 100, 'spend': 251, 'online': 199, 'interest': 132, 'news': 191, 'give': 108, 'part': 201, 'able': 6, 'control': 59, 'open': 200, 'world': 295, 'sign': 247, 'around': 17, 'say mr': 236, 'bbc': 24, 'man': 164, 'point': 211, 'place': 206, 'unite': 280, 'club': 53, 'ask': 18, 'title': 272, 'return': 229, 'early': 75, 'remain': 226, 'suggest': 257, 'plan': 207, 'offer': 194, 'final': 93, '2004': 4, 'prime': 216, 'close': 52, 'talk': 261, 'another': 16, 'lead': 147, 'build': 40, 'know': 140, 'day': 68, 'team': 263, 'really': 223, 'money': 176, 'allow': 11, 'try': 275, 'best': 29, 'players': 210, 'move': 179, 'prime minister': 217, 'turn': 276, 'lose': 160, 'video': 284, 'believe': 28, 'record': 224, 'run': 233, 'match': 167, 'issue': 136, 'half': 116, 'big': 31, 'tell': 265, 'star': 253, '2005': 5, 'good': 110, 'film': 92, 'act': 8, 'director': 74, 'tv': 277, 'blair': 34, 'brown': 39, 'general': 106, 'election': 78, 'britain': 37, 'concern': 57, '2003': 3, 'howard': 126, 'need': 187, 'grow': 114, 'tell bbc': 266, 'mr blair': 181, 'vote': 285, 'result': 228, 'award': 20, 'week': 290, 'show': 245, 'warn': 288, 'countries': 62, 'industry': 130, 'group': 113, 'increase': 129, 'sales': 234, 'release': 225, 'office': 195, 'network': 189, 'house': 125, 'last year': 143, 'cup': 66, 'four': 102, 'without': 293, 'share': 244, '10': 1, 'start': 254, 'launch': 145, 'attack': 19, 'lord': 159, 'bring': 36, 'away': 21, 'radio': 221, 'national': 185, 'campaign': 44, 'growth': 115, 'fall': 88, 'economy': 77, 'economic': 76, 'wales': 286, 'second': 237, 'beat': 25, 'england': 80, 'france': 103, 'trade': 274, 'third': 269, 'information': 131, 'technology': 264, 'program': 218, 'power': 213, 'software': 250, 'microsoft': 172, 'computer': 56}\n"
     ]
    }
   ],
   "source": [
    "print(tfidf.fit(X_train).vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>000</th>\n",
       "      <th>10</th>\n",
       "      <th>12</th>\n",
       "      <th>2003</th>\n",
       "      <th>2004</th>\n",
       "      <th>2005</th>\n",
       "      <th>able</th>\n",
       "      <th>accord</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>...</th>\n",
       "      <th>week</th>\n",
       "      <th>well</th>\n",
       "      <th>win</th>\n",
       "      <th>without</th>\n",
       "      <th>work</th>\n",
       "      <th>world</th>\n",
       "      <th>would</th>\n",
       "      <th>year</th>\n",
       "      <th>year old</th>\n",
       "      <th>years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.083760</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.076326</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.13694</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.070291</td>\n",
       "      <td>0.135187</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.122948</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.054789</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.101258</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.129174</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.094337</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.156228</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.065335</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083359</td>\n",
       "      <td>0.076422</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060166</td>\n",
       "      <td>0.057208</td>\n",
       "      <td>0.043577</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.057208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        000   10        12  2003  2004  2005      able    accord  act  \\\n",
       "0  0.083760  0.0  0.000000   0.0   0.0   0.0  0.000000  0.000000  0.0   \n",
       "1  0.000000  0.0  0.000000   0.0   0.0   0.0  0.000000  0.000000  0.0   \n",
       "2  0.000000  0.0  0.000000   0.0   0.0   0.0  0.000000  0.000000  0.0   \n",
       "3  0.101258  0.0  0.129174   0.0   0.0   0.0  0.000000  0.000000  0.0   \n",
       "4  0.000000  0.0  0.000000   0.0   0.0   0.0  0.083359  0.076422  0.0   \n",
       "\n",
       "    action  ...  week      well       win  without      work     world  \\\n",
       "0  0.00000  ...   0.0  0.000000  0.000000      0.0  0.076326  0.000000   \n",
       "1  0.13694  ...   0.0  0.000000  0.000000      0.0  0.000000  0.000000   \n",
       "2  0.00000  ...   0.0  0.000000  0.122948      0.0  0.000000  0.000000   \n",
       "3  0.00000  ...   0.0  0.094337  0.000000      0.0  0.156228  0.000000   \n",
       "4  0.00000  ...   0.0  0.000000  0.000000      0.0  0.060166  0.057208   \n",
       "\n",
       "      would      year  year old     years  \n",
       "0  0.000000  0.000000  0.000000  0.000000  \n",
       "1  0.000000  0.070291  0.135187  0.000000  \n",
       "2  0.054789  0.000000  0.000000  0.000000  \n",
       "3  0.000000  0.065335  0.000000  0.000000  \n",
       "4  0.043577  0.000000  0.000000  0.057208  \n",
       "\n",
       "[5 rows x 300 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix = pd.DataFrame(features_train, columns=tfidf.get_feature_names())\n",
    "tfidf_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 'Business' category:\n",
      "  . Most correlated unigrams:\n",
      ". economic\n",
      ". economy\n",
      ". oil\n",
      ". growth\n",
      ". bank\n",
      "  . Most correlated bigrams:\n",
      ". mr blair\n",
      ". year old\n",
      "\n",
      "# 'Entertainment' category:\n",
      "  . Most correlated unigrams:\n",
      ". best\n",
      ". music\n",
      ". star\n",
      ". award\n",
      ". film\n",
      "  . Most correlated bigrams:\n",
      ". mr blair\n",
      ". prime minister\n",
      "\n",
      "# 'Politics' category:\n",
      "  . Most correlated unigrams:\n",
      ". minister\n",
      ". blair\n",
      ". party\n",
      ". election\n",
      ". labour\n",
      "  . Most correlated bigrams:\n",
      ". prime minister\n",
      ". mr blair\n",
      "\n",
      "# 'Sport' category:\n",
      "  . Most correlated unigrams:\n",
      ". game\n",
      ". club\n",
      ". team\n",
      ". cup\n",
      ". match\n",
      "  . Most correlated bigrams:\n",
      ". say mr\n",
      ". year old\n",
      "\n",
      "# 'Technology' category:\n",
      "  . Most correlated unigrams:\n",
      ". microsoft\n",
      ". technology\n",
      ". computer\n",
      ". software\n",
      ". users\n",
      "  . Most correlated bigrams:\n",
      ". year old\n",
      ". say mr\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import chi2\n",
    "import numpy as np\n",
    "\n",
    "for Product, category_id in sorted(category_codes.items()):\n",
    "    features_chi2 = chi2(features_train, labels_train == category_id)\n",
    "    indices = np.argsort(features_chi2[0])\n",
    "    feature_names = np.array(tfidf.get_feature_names())[indices]\n",
    "    unigrams = [v for v in feature_names if len(v.split(' ')) == 1]\n",
    "    bigrams = [v for v in feature_names if len(v.split(' ')) == 2]\n",
    "    print(\"# '{}' category:\".format(Product))\n",
    "    print(\"  . Most correlated unigrams:\\n. {}\".format('\\n. '.join(unigrams[-5:])))\n",
    "    print(\"  . Most correlated bigrams:\\n. {}\".format('\\n. '.join(bigrams[-2:])))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickling \n",
    "import pickle\n",
    "\n",
    "# X_train\n",
    "with open('Pickles/X_train.pickle', 'wb') as output:\n",
    "    pickle.dump(X_train, output)\n",
    "    \n",
    "# X_test    \n",
    "with open('Pickles/X_test.pickle', 'wb') as output:\n",
    "    pickle.dump(X_test, output)\n",
    "    \n",
    "# y_train\n",
    "with open('Pickles/y_train.pickle', 'wb') as output:\n",
    "    pickle.dump(y_train, output)\n",
    "    \n",
    "# y_test\n",
    "with open('Pickles/y_test.pickle', 'wb') as output:\n",
    "    pickle.dump(y_test, output)\n",
    "    \n",
    "# news_data\n",
    "with open('Pickles/news_data.pickle', 'wb') as output:\n",
    "    pickle.dump(news_data, output)\n",
    "    \n",
    "# features_train\n",
    "with open('Pickles/features_train.pickle', 'wb') as output:\n",
    "    pickle.dump(features_train, output)\n",
    "\n",
    "# labels_train\n",
    "with open('Pickles/labels_train.pickle', 'wb') as output:\n",
    "    pickle.dump(labels_train, output)\n",
    "\n",
    "# features_test\n",
    "with open('Pickles/features_test.pickle', 'wb') as output:\n",
    "    pickle.dump(features_test, output)\n",
    "\n",
    "# labels_test\n",
    "with open('Pickles/labels_test.pickle', 'wb') as output:\n",
    "    pickle.dump(labels_test, output)\n",
    "    \n",
    "# TF-IDF object\n",
    "with open('Pickles/tfidf.pickle', 'wb') as output:\n",
    "    pickle.dump(tfidf, output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
